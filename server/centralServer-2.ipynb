{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf1eebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import argparse\n",
    "import concurrent.futures\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import spur\n",
    "import subprocess\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "sns.set()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3e7a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create the keras model (LR in this case)\n",
    "def create_keras_model():\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=0)\n",
    "    ##build LR model\n",
    "    number_of_classes = 1\n",
    "    number_of_features = 27\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes,activation = 'sigmoid',input_dim = number_of_features))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c2855c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_clients(client, path):\n",
    "    ##clear models from clients\n",
    "    command = f'rm -rf {path}{client}/model/*'\n",
    "    command.split(' ')\n",
    "    subprocess.call(command, shell = True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f474c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clients(client, path, dir, epochs, test):\n",
    "    ##send model to clients\n",
    "    if test:\n",
    "        command = f'cp -r {dir}/model/server_models/best_model/* {path}{client}/model'\n",
    "        subprocess.call(command, shell = True) \n",
    "    else:\n",
    "        command = f'cp -r {dir}/model/server_models/current_model/* {path}{client}/model'\n",
    "        subprocess.call(command, shell = True) \n",
    "    \n",
    "    ##Run script\n",
    "    command = f'python {path}{client}/clientServer-2.py -cl={client} -ep={epochs} -ts={test}'\n",
    "    command = command.split(' ')\n",
    "    output = subprocess.check_output(command) \n",
    "    server_response = output.decode('utf-8').split(' ')\n",
    "    return server_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f0b12a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fedAvg(server_1_model, server_2_model, relative_weights):\n",
    "    weights = [server_1_model.get_weights(), server_2_model.get_weights()]\n",
    "    new_weights = []\n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        new_weights.append(np.array([np.average(np.array(\n",
    "            weights_), axis=0, weights=relative_weights) for weights_ in zip(*weights_list_tuple)]))\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5051dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateResults(server_1_response, server_2_response):\n",
    "    # Check if the current validation is better than the previous best one\n",
    "    relative_weights = [server_1_response[0] / (server_1_response[0] + server_2_response[0]),\n",
    "                        server_2_response[0] / (server_1_response[0] + server_2_response[0])]\n",
    "\n",
    "    current_validation = server_1_response[3] * relative_weights[0] + server_2_response[3] * relative_weights[1]\n",
    "    \n",
    "    current_auc = server_1_response[4] * relative_weights[0] + server_2_response[4] * relative_weights[1]\n",
    "    \n",
    "    return relative_weights, current_validation, current_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cd119593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8108776211738586 Validation AUC: 0.5109588205814362\n",
      "Validation Loss: 0.5953134596347809 Validation AUC: 0.7193323075771332\n",
      "Validation Loss: 0.5531604588031769 Validation AUC: 0.7609407305717468\n",
      "Validation Loss: 0.5467419326305389 Validation AUC: 0.7639023661613464\n",
      "Validation Loss: 0.54527547955513 Validation AUC: 0.7643387913703918\n",
      "Validation Loss: 0.5447752177715302 Validation AUC: 0.7657925486564636\n",
      "Validation Loss: 0.5447184145450592 Validation AUC: 0.7662441730499268\n",
      "Validation Loss: 0.5444793403148651 Validation AUC: 0.7673182189464569\n",
      "Test AUC: 0.7870136499404907\n"
     ]
    }
   ],
   "source": [
    "centralServer = 'pe2cc3-002'\n",
    "clientServer_1 = 'pe2cc3-002'\n",
    "clientServer_2 = 'pe2cc3-002'\n",
    "\n",
    "client_1 = 'client_1'\n",
    "client_2 = 'client_2'\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "patience = 2\n",
    "epochs = 20\n",
    "\n",
    "##load directory\n",
    "__file__ = 'centralServer.ipynb'\n",
    "dir = os.path.abspath(os.path.dirname(__file__))\n",
    "path = '/gpfs/commons/groups/gursoy_lab/aelhussein/DCI_FL/'\n",
    "\n",
    "# Delete past client data\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    command_1 = executor.submit(\n",
    "        clear_clients, client_1, path)\n",
    "    command_2 = executor.submit(\n",
    "        clear_clients, client_2, path)\n",
    "\n",
    "# Model architecture\n",
    "federated_model = create_keras_model()\n",
    "federated_model.save(f'{path}server/model/server_models/current_model')\n",
    "federated_model.save(f'{path}server/model/server_models/best_model')\n",
    "\n",
    "# Set runtime parameters\n",
    "patience_counter = 0\n",
    "iterations = 0\n",
    "lowest_validation = float('inf')\n",
    "early_stopping = False\n",
    "test = False\n",
    "while (early_stopping == False) and (iterations < 10):\n",
    "    # Run model\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        command_1 = executor.submit(run_clients, client_1, path, dir, epochs, test)\n",
    "        command_2 = executor.submit(run_clients, client_2, path, dir, epochs, test)\n",
    "\n",
    "        # Retrieve server responses\n",
    "        server_1_response = [float(j) for j in command_1.result()]\n",
    "        server_2_response = [float(j) for j in command_2.result()]\n",
    "    # Wait until the two servers return their weights files\n",
    "    while (os.path.isfile(path + 'server/model/client_models/client_1/saved_model.pb') == False or\n",
    "               os.path.isfile(path + 'server/model/client_models/client_2/saved_model.pb' == False)):\n",
    "        time.sleep(5)\n",
    "\n",
    "    relative_weights, current_validation, current_auc = validateResults(server_1_response, server_2_response)\n",
    "    if current_validation < lowest_validation:\n",
    "        patience_counter = 0\n",
    "        federated_model.save(f'{path}server/model/server_models/best_model')\n",
    "        lowest_validation = current_validation\n",
    "        print(f'Validation Loss: {current_validation} Validation AUC: {current_auc}')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # Conduct federated averaging to update the federated_model if we have not exceeded patience\n",
    "    if patience_counter > patience:\n",
    "        early_stopping = True\n",
    "        test = True\n",
    "    else:\n",
    "        server_1_model = tf.keras.models.load_model(path + 'server/model/client_models/client_1/')\n",
    "        server_2_model = tf.keras.models.load_model(path + 'server/model/client_models/client_2/')\n",
    "        new_weights = fedAvg(server_1_model, server_2_model, relative_weights)\n",
    "        federated_model.set_weights(new_weights)\n",
    "        federated_model.save(f'{path}server/model/server_models/current_model')\n",
    "    iterations +=1\n",
    "    \n",
    "    if iterations >= 10:\n",
    "        test = True\n",
    "\n",
    "if test:\n",
    "     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        command_1 = executor.submit(run_clients, client_1, path, dir, epochs, test)\n",
    "        command_2 = executor.submit(run_clients, client_2, path, dir, epochs, test)\n",
    "\n",
    "        # Retrieve server responses\n",
    "        server_1_response = [float(j) for j in command_1.result()]\n",
    "        server_2_response = [float(j) for j in command_2.result()]\n",
    "        \n",
    "        relative_weights, current_validation, current_auc = validateResults(server_1_response, server_2_response)\n",
    "        \n",
    "        print(f'Test AUC: {current_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-s0','--centralServer', default = '')\n",
    "    parser.add_argument('-s1','--clientServer_1', default = '')\n",
    "    parser.add_argument('-s2','--clientServer_2', default = '')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    centralServer = args.centralServer\n",
    "    clientServer_1 = args.clientServer_1\n",
    "    clientServer_2 = args.clientServer_2\n",
    "    \n",
    "client_1 = 'client_1'\n",
    "client_2 = 'client_2'\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "patience = 2\n",
    "epochs = 20\n",
    "\n",
    "##load directory\n",
    "__file__ = 'centralServer.ipynb'\n",
    "dir = os.path.abspath(os.path.dirname(__file__))\n",
    "path = '/gpfs/commons/groups/gursoy_lab/aelhussein/DCI_FL/'\n",
    "\n",
    "# Delete past client data\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    command_1 = executor.submit(\n",
    "        clear_clients, client_1, path)\n",
    "    command_2 = executor.submit(\n",
    "        clear_clients, client_2, path)\n",
    "\n",
    "# Model architecture\n",
    "federated_model = create_keras_model()\n",
    "federated_model.save(f'{path}server/model/server_models/current_model')\n",
    "federated_model.save(f'{path}server/model/server_models/best_model')\n",
    "\n",
    "# Set runtime parameters\n",
    "patience_counter = 0\n",
    "iterations = 0\n",
    "lowest_validation = float('inf')\n",
    "early_stopping = False\n",
    "test = False\n",
    "while (early_stopping == False) and (iterations < 10):\n",
    "    # Run model\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        command_1 = executor.submit(run_clients, client_1, path, dir, epochs, test)\n",
    "        command_2 = executor.submit(run_clients, client_2, path, dir, epochs, test)\n",
    "\n",
    "        # Retrieve server responses\n",
    "        server_1_response = [float(j) for j in command_1.result()]\n",
    "        server_2_response = [float(j) for j in command_2.result()]\n",
    "    # Wait until the two servers return their weights files\n",
    "    while (os.path.isfile(path + 'server/model/client_models/client_1/saved_model.pb') == False or\n",
    "               os.path.isfile(path + 'server/model/client_models/client_2/saved_model.pb' == False)):\n",
    "        time.sleep(5)\n",
    "\n",
    "    relative_weights, current_validation, current_auc = validateResults(server_1_response, server_2_response)\n",
    "    if current_validation < lowest_validation:\n",
    "        patience_counter = 0\n",
    "        federated_model.save(f'{path}server/model/server_models/best_model')\n",
    "        lowest_validation = current_validation\n",
    "        print(f'Validation Loss: {current_validation} Validation AUC: {current_auc}')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # Conduct federated averaging to update the federated_model if we have not exceeded patience\n",
    "    if patience_counter > patience:\n",
    "        early_stopping = True\n",
    "        test = True\n",
    "    else:\n",
    "        server_1_model = tf.keras.models.load_model(path + 'server/model/client_models/client_1/')\n",
    "        server_2_model = tf.keras.models.load_model(path + 'server/model/client_models/client_2/')\n",
    "        new_weights = fedAvg(server_1_model, server_2_model, relative_weights)\n",
    "        federated_model.set_weights(new_weights)\n",
    "        federated_model.save(f'{path}server/model/server_models/current_model')\n",
    "    iterations +=1\n",
    "    \n",
    "    if iterations >= 10:\n",
    "        test = True\n",
    "\n",
    "if test:\n",
    "     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        command_1 = executor.submit(run_clients, client_1, path, dir, epochs, test)\n",
    "        command_2 = executor.submit(run_clients, client_2, path, dir, epochs, test)\n",
    "\n",
    "        # Retrieve server responses\n",
    "        server_1_response = [float(j) for j in command_1.result()]\n",
    "        server_2_response = [float(j) for j in command_2.result()]\n",
    "        \n",
    "        relative_weights, current_validation, current_auc = validateResults(server_1_response, server_2_response)\n",
    "        \n",
    "        print(f'Test AUC: {current_auc}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
