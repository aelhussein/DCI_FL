{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf1eebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import argparse\n",
    "import concurrent.futures\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import spur\n",
    "import subprocess\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import _pickle as cPickle\n",
    "sns.set()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e7a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create the keras model (LR in this case)\n",
    "def create_RF_model(path):\n",
    "    model = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "    with open(f'{path}server/model/server_models/current_model/RF/RF', 'wb') as f:\n",
    "        cPickle.dump(model, f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "286549b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the rf  model\n",
    "def save_RF_model(location, client_model):\n",
    "    with open(location, 'wb') as f:\n",
    "        cPickle.dump(client_model, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208bbd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the rf  model\n",
    "def load_RF_model(location):\n",
    "    with open(location, 'rb') as f:\n",
    "        return  cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2855c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_clients(client, path):\n",
    "    ##clear models from clients\n",
    "    command = f'rm -rf {path}{client}/model/RF/*'\n",
    "    command.split(' ')\n",
    "    subprocess.call(command, shell = True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f474c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clients(client, path, dir, test):\n",
    "    ##send model to clients\n",
    "    command = f'cp -r {dir}/model/server_models/current_model/RF/* {path}{client}/model/RF/'\n",
    "    subprocess.call(command, shell = True) \n",
    "    \n",
    "    ##Run script\n",
    "    command = f'python {path}{client}/clientServer-RF.py -cl={client} -ts={test}'\n",
    "    command = command.split(' ')\n",
    "    output = subprocess.check_output(command) \n",
    "    server_response = output.decode('utf-8').split(' ')\n",
    "    return server_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b12a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fedAvg(server_1_model, server_2_model, relative_weights):\n",
    "    ##extract individual trees\n",
    "    client_trees = [server_1_model.estimators_, server_2_model.estimators_]\n",
    "    ##assign number of trees\n",
    "    num_trees = [round(len(client_trees[0])*weight) for weight in relative_weights]\n",
    "    ##sample from both forests\n",
    "    new_forest = []\n",
    "    for i in range(len(client_trees)):\n",
    "        new_forest.extend(list(np.random.choice(client_trees[i], num_trees[i])))\n",
    "    ##assign to models\n",
    "    server_1_model.estimators_ = new_forest\n",
    "    server_2_model.estimators_ = new_forest\n",
    "    return server_1_model, server_2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5051dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateResults(server_1_response, server_2_response):\n",
    "    # Check if the current validation is better than the previous best one\n",
    "    relative_weights = [server_1_response[0] / (server_1_response[0] + server_2_response[0]),\n",
    "                        server_2_response[0] / (server_1_response[0] + server_2_response[0])]\n",
    "\n",
    "    current_auc = server_1_response[2] * relative_weights[0] + server_2_response[2] * relative_weights[1]\n",
    "\n",
    "    \n",
    "    return relative_weights, current_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-s0','--centralServer', default = '')\n",
    "    parser.add_argument('-s1','--clientServer_1', default = '')\n",
    "    parser.add_argument('-s2','--clientServer_2', default = '')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    centralServer = args.centralServer\n",
    "    clientServer_1 = args.clientServer_1\n",
    "    clientServer_2 = args.clientServer_2\n",
    "    \n",
    "    client_1 = 'client_1'\n",
    "    client_2 = 'client_2'\n",
    "\n",
    "    ##load directory\n",
    "    __file__ = 'centralServer.ipynb'\n",
    "    dir = os.path.abspath(os.path.dirname(__file__))\n",
    "    path = '/gpfs/commons/groups/gursoy_lab/aelhussein/DCI_FL/'\n",
    "    \n",
    "\n",
    "    # Delete past client data\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        command_1 = executor.submit(\n",
    "            clear_clients, client_1, path)\n",
    "        command_2 = executor.submit(\n",
    "            clear_clients, client_2, path)\n",
    "\n",
    "    # Model architecture\n",
    "    model = create_RF_model(path)\n",
    "    # Set runtime parameters\n",
    "    test = False\n",
    "    # Run model\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        command_1 = executor.submit(run_clients, client_1, path, dir, test)\n",
    "        command_2 = executor.submit(run_clients, client_2, path, dir, test)\n",
    "\n",
    "        # Retrieve server responses\n",
    "        server_1_response = [float(j) for j in command_1.result()]\n",
    "        server_2_response = [float(j) for j in command_2.result()]\n",
    "\n",
    "    # Wait until the two servers return their weights files\n",
    "    while (os.path.isfile(path + 'server/model/client_models/client_1/RF/RF') == False or\n",
    "               os.path.isfile(path + 'server/model/client_models/client_2/RF/RF' == False)):\n",
    "        time.sleep(5)\n",
    "\n",
    "    # Calculate weights and AUC\n",
    "    relative_weights, current_auc = validateResults(server_1_response, server_2_response)\n",
    "    print(f'Validation AUC: {current_auc}')\n",
    "\n",
    "    # Load models\n",
    "    server_1_model = load_RF_model(f'{path}server/model/client_models/client_1/RF/RF')\n",
    "    server_2_model = load_RF_model(f'{path}server/model/client_models/client_2/RF/RF')\n",
    "\n",
    "    # Conduct federated averaging to update the federated_model\n",
    "    server_1_model, server_2_model = fedAvg(server_1_model, server_2_model, relative_weights)\n",
    "    save_RF_model(f'{path}server/model/server_models/current_model/RF/RF', server_1_model)\n",
    "    # Save the model in best_model for ensemble learning\n",
    "    save_RF_model(f'{path}server/model/server_models/best_model/RF/RF', server_1_model)\n",
    "\n",
    "    test = True\n",
    "\n",
    "    if test:\n",
    "         with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            command_1 = executor.submit(run_clients, client_1, path, dir, test)\n",
    "            command_2 = executor.submit(run_clients, client_2, path, dir, test)\n",
    "\n",
    "            # Retrieve server responses\n",
    "            server_1_response = [float(j) for j in command_1.result()]\n",
    "            server_2_response = [float(j) for j in command_2.result()]\n",
    "\n",
    "            relative_weights, current_auc = validateResults(server_1_response, server_2_response)\n",
    "\n",
    "            print(f'Test AUC: {current_auc}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
